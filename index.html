<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>David Porfirio</title>
<link rel="stylesheet" type="text/css" href="css/index.css">
</head>

<body>
<br/>

<hr style="width: 60%"/>

<div class="row">
	<div class="column_left"> <br/>
		<img src="content/me.png" alt="portrait" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		<text>
			
			<h3 style="text-align: left; margin-bottom: 0px;">
				<par><font size="3px">David Porfirio</font></par>
				<br><a href="dporfirio@wisc.edu">dporfirio@wisc.edu</a>
				<br><a href="http://hci.cs.wisc.edu/">People and Robots Lab</a>
				<br><a href="https://www.cs.wisc.edu/">Computer Sciences Department</a>
				<br><a href="https://www.wisc.edu//">University of Wisconsin–Madison</a>
				<br><br><a href="content/CV.pdf">Download my CV</a>
			</h3>
		</text>
	</div>
	<div class="column_right"> <br/>
		<text>
			<par>About Me</par><br>
			I'm a PhD candidate at the University of Wisconsin–Madison, and my goal is to investigate and build new technologies that can help people program social robots. To do that, I create software and hardware interfaces that capture the intent of interaction designers and developers and convert their intent into programs by means of program verification and synthesis.
			
			<br><br>
			I am mentored by <a href="http://pages.cs.wisc.edu/~bilge/">Bilge Mutlu</a>, <a href="http://pages.cs.wisc.edu/~aws/">Aws Albarghouthi</a>, <a href="https://www.uwlax.edu/profile/asauppe/">Allison Sauppé</a>, and <a href="https://homes.cs.washington.edu/~mcakmak/">Maya Cakmak</a>.
			<br>
			<br>
			Some recent updates:<br>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>1.21.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					Figaro, our tabletop HRI authoring environment, has been accepted to CHI.
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>12.19.20</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I presented my research at <a href="https://talking-robotics.github.io/">Talking Robotics</a>.
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>9.23.20</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I attended the <a href="https://www.microsoft.com/en-us/research/event/ai-breakthroughs-2020/">Microsoft Research AI Breakthroughs</a> event.
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>6.20.20</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I completed my preliminary examination and am officially a dissertator!
				</div>
			</div>
		  <br>
<br>
		</text>
	</div>
</div>

<br/>
<hr style="width: 60%"/>

<div class="row">
	<div class="column_right"><br/>
		<par>Projects</par>
	</div>
</div>
<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/figurines.JPG" alt="repair" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Figaro: A Tabletop Authoring Environment for Human-Robot Interaction
				<text style="font-size: 12px;">
					(in press)
				</text>
			</h4>
			<!--img src="content/me.jpg" alt="portrait" style="padding: 10px; vertical-align: top;" align="right" height="200"-->
			We constructed Figaro, a tabletop authoring environment that in which demonstrators use figurines to play out scenes of human-robot interactions. FIn each scene, Figaro records the positions, movement, and speech of the figurines, in addition to actions enacted on the figurines themselves, in order to synthesize a full human-robot interaction program that can be executed on a robot.
		</text>
	</div>
</div>
	<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/repair.JPG" alt="repair" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Transforming Robot Programs Based on Social Context 
				<text style="font-size: 12px;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/chi20.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=fh8qZip4Ruc&ab_channel=ACMSIGCHI">video</a>, <a href="https://github.com/Wisc-HCI/interaction-transformation">github</a>
				</text>
			</h4>
			<!--img src="content/me.jpg" alt="portrait" style="padding: 10px; vertical-align: top;" align="right" height="200"-->
			We developed a novel method for automatically making modifications to a robot program after the program has been deployed on a physical robot. The goal of the modifications is to maximize user experience for a specific interaction context, while maintaining adherence to a prespecified set of baseline context-free social norms.
		</text>
	</div>
</div>
<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/bodystorming.JPG" alt="synthe" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Bodystorming Human-Robot Interactions 
				<text style="font-size: 12px;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/uist19.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=4mml_6Dw7kU&ab_channel=ACMSIGCHI">video</a>, <a href="https://github.com/Wisc-HCI/Synthe">github</a>
				</text>
			</h4>
			<!--img src="content/me.jpg" alt="portrait" style="padding: 10px; vertical-align: top;" align="right" height="200"-->
			We developed a programming environment, Synthé, that enables design teams to act out, or bodystorm, human robot interactions. Designer demonstrations are converted to execution traces, which are then used as input to an inductive synthesis algorithm which synthesizes a full human-robot interaction program from scratch.
		</text>
	</div>
</div>
<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/tool-annotated.jpg" alt="rover" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Authoring and Verifying Human-Robot Interactions
			<text style="font-size: 12px;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/uist18.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=3Kj5mJ0GmLk&ab_channel=ACMSIGCHI">video</a>, <a href="https://github.com/Wisc-HCI/RoVer">github</a>
				</text>
			</h4>
			We developed a visual programming environment that allows people to design human-robot interaction programs and receive feedback in real-time on whether these programs violate social norms. In order to provide this feedback, we model in-progress human-robot interaction programs as transition systems, and a set of context-specific social norms within temporal logic. The transition systems and social norms are then input into an off-the-shelf model checker.
		</text>
	</div>
</div>
<h4></h4>
<hr style="width: 60%"/>
</body>
</html>
