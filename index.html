<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>David Porfirio</title>
<link rel="stylesheet" type="text/css" href="css/index.css">
</head>

<body>
<br/>

<hr style="width: 60%"/>

<div class="row">
	<div class="column_left"> <br/>
		<img src="content/me.png" alt="portrait" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		<text>
			
			<h3 style="text-align: left; margin-bottom: 0px;">
				<par><font size="3px">David Porfirio</font></par>
				<br><a href="mailto: dporfirio@wisc.edu">dporfirio@wisc.edu</a>
				<br><a href="https://peopleandrobots.wisc.edu/">People and Robots Lab</a>
				<br><a href="https://www.cs.wisc.edu/">Computer Sciences Department</a>
				<br><a href="https://www.wisc.edu/">University of Wisconsin‚ÄìMadison</a>
				<br><br><a href="content/CV.pdf">Download my CV</a>
			</h3>
		</text>
	</div>
	<div class="column_right"> <br/>
		<text>
			<par>I'm a PhD Candidate at UW‚ÄìMadison!</par><br>
			My research is about helping people program social and service robots. To do that, I create software and hardware interfaces that (1) capture the intent of interaction designers and end-user developers and then (2) employ program verification or synthesis in order to help designers and developers assemble complete robot programs. 
			
			<br><br>
			I am mentored by <a href="http://pages.cs.wisc.edu/~bilge/">Bilge Mutlu</a>, <a href="http://pages.cs.wisc.edu/~aws/">Aws Albarghouthi</a>, <a href="https://www.uwlax.edu/profile/asauppe/">Allison Saupp√©</a>, and <a href="https://homes.cs.washington.edu/~mcakmak/">Maya Cakmak</a>.
			<br>
			<br>
			Some recent updates:<br>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>11.9.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I presented my in-progress work at <a href="https://2021.plateau-workshop.org">PLATEAU 2021</a>.
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>6.7.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I began a 10-week internship at <a href="https://www.bell-labs.com/#gref">Nokia Bell Labs</a>!
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>5.24.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I am a <a href="https://www.microsoft.com/en-us/research/academic-program/dissertation-grant/#!grant-recipients">2021 Microsoft Research Dissertation Grant Recipient</a>!
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>5.7.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I received a <a href="https://www.cs.wisc.edu/2021-cs-department-awards-and-thank-yous/">Cisco Graduate Student Fellowship</a> at UW‚ÄìMadison!
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>5.11.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					I presented <a href="https://www.youtube.com/watch?v=7ox53gOHx4I&t=2s">Figaro</a>, our tabletop authoring environment, at CHI 2021.
				</div>
			</div>
			<div class="row" style="width: 100%;">
				<div class="column_left" style="width: 15%;">
					<par>1.21.21</par>
				</div>
				<div class="column_right" style="width: 85%;">
					Figaro, our tabletop HRI authoring environment, has been accepted to CHI 2021.
				</div>
			</div>
		  <br>
<br>
		</text>
	</div>
</div>

<br/>
<hr style="width: 60%"/>

<div class="row">
	<div class="column_right"><br/>
		<par>Research Projects</par>
	</div>
</div>
<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/figurines.JPG" alt="repair" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Figaro: A Tabletop Authoring Environment for Human-Robot Interaction</h4>
			<h4 style="margin:0px; font-weight:bold;">
				CHI 2021
				<text style="font-size: 12px; font-weight:normal;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/chi21.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=7ox53gOHx4I&list=PLqhXYFYmZ-Vez20PWol8EVmJDmpr9DdPG&index=449">video</a>, <a href="https://github.com/Wisc-HCI/Figaro">github</a>
				</text>
			</h4>
			<!--img src="content/me.jpg" alt="portrait" style="padding: 10px; vertical-align: top;" align="right" height="200"-->
			Figaro is a tabletop authoring environment in which demonstrators use figurines to play out scenes of human-robot interactions. In each scene, Figaro records the positions, movement, and speech of the figurines, in addition to actions enacted on the figurines themselves. Figaro then synthesizes a full human-robot interaction program that can be executed on a robot.
		</text>
	</div>
</div>
	<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/repair.JPG" alt="repair" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Transforming Robot Programs Based on Social Context</h4>
			<h4 style="margin:0px; font-weight:bold;">
				CHI 2020
				<text style="font-size: 12px; font-weight:normal;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/chi20.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=fh8qZip4Ruc&ab_channel=ACMSIGCHI">video</a>, <a href="https://github.com/Wisc-HCI/interaction-transformation">github</a>
				</text>
			</h4>
			<!--img src="content/me.jpg" alt="portrait" style="padding: 10px; vertical-align: top;" align="right" height="200"-->
			We developed a novel method for automatically making modifications to a robot program after the program has been deployed on a physical robot. The goal of the modifications is to maximize user experience for a specific interaction context, while maintaining adherence to a prespecified set of baseline context-free social norms.
		</text>
	</div>
</div>
<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/bodystorming.JPG" alt="synthe" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Bodystorming Human-Robot Interactions </h4>
			<h4 style="margin:0px; font-weight:bold;">
				UIST 2019
				<text style="font-size: 12px; font-weight:normal;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/uist19.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=4mml_6Dw7kU&ab_channel=ACMSIGCHI">video</a>, <a href="https://github.com/Wisc-HCI/Synthe">github</a>
				</text>
			</h4>
			<!--img src="content/me.jpg" alt="portrait" style="padding: 10px; vertical-align: top;" align="right" height="200"-->
			We developed a programming environment, Synth√©, that enables design teams to act out, or bodystorm, human robot interactions. Designer demonstrations are converted to execution traces, which are then used as input to an inductive synthesis algorithm which synthesizes a full human-robot interaction program from scratch.
		</text>
	</div>
</div>
<br/>
<div class="row">
	<div class="column_left">
		<text>
			<h4></h4>
			<img src="content/tool-annotated.jpg" alt="rover" style="padding-right: 30px; padding-top: 5px; vertical-align: top;" width="200">
		</text>
	</div>
	<div class="column_right">
		<text>
			<h4>Authoring and Verifying Human-Robot Interactions</h4>
			<h4 style="margin:0px; font-weight:bold;">
				üèÜ UIST 2018 (Best Paper Award)
				<text style="font-size: 12px; font-weight:normal;">
					<a href="http://pages.cs.wisc.edu/~aws/papers/uist18.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=3Kj5mJ0GmLk&ab_channel=ACMSIGCHI">video</a>, <a href="https://github.com/Wisc-HCI/RoVer">github</a>
				</text>
			</h4>
			We developed a visual programming environment that allows people to design human-robot interaction programs and receive feedback in real-time on whether these programs violate social norms. In order to provide this feedback, we model in-progress human-robot interaction programs as transition systems, and a set of context-specific social norms within temporal logic. The transition systems and social norms are then input into an off-the-shelf model checker.
		</text>
	</div>
</div>
<h4></h4>
<hr style="width: 60%"/>
</body>
</html>
